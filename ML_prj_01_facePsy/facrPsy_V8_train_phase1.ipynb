{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJZOaNJZJ9rO",
        "outputId": "98a0b324-e42d-4f90-ac48-f5216560578a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks\n",
            "/content/drive/MyDrive/Colab Notebooks\n",
            " basic_operations.ipynb\t\t\t     som_trained_data_02.pkl\n",
            " cnn_raw.py\t\t\t\t     test_data_compressed.pkl\n",
            " colab_basics.ipynb\t\t\t     train_data_compressed.pkl\n",
            " compressed_file.pkl\t\t\t     trained_som.pkl\n",
            "'Copy of 1_preprocessing_MJR - Copy.ipynb'   train_som_iteration_1_img.pkl\n",
            " DREAM_DATA_view.ipynb\t\t\t     train_som_iteration_1.pkl\n",
            " DREAMER.mat\t\t\t\t     train_som_iteration_2_img.pkl\n",
            " extracted_face_data\t\t\t     train_som_iteration_2.pkl\n",
            " facrPsy_V7_trainTestSample.ipynb\t     train_som_iteration_3_img.pkl\n",
            " facrPsy_V8_train_phase1.ipynb\t\t     train_som_iteration_3.pkl\n",
            " probability_vectors.pkl\t\t     Untitled\n",
            " som_trained_data_01.pkl\t\t     unzip_files.ipynb\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# change directories:\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks\n",
        "!pwd    # current working directory now changed\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AodJ5z1PMX6t"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from skimage.color import rgb2gray\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nT7VvZR7Kzkr"
      },
      "outputs": [],
      "source": [
        "\n",
        "extracted_data_path = './extracted_face_data/'\n",
        "\n",
        "patient_id = ['P08', 'P08', 'P10', 'P10', 'P12', 'P12', 'P13', 'P13', 'P14', 'P15', 'P15', 'P16', 'P16', 'P17', 'P17', 'P18', 'P18', 'P19', 'P19', 'P20', 'P20', 'P21', 'P21', 'P23', 'P23', 'P24', 'P24', 'P25', 'P27', 'P28', 'P29', 'P29', 'P30', 'P30', 'P31', 'P31', 'P33', 'P33', 'P34', 'P35', 'P35', 'P36', 'P38', 'P38']\n",
        "ground_truth = [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "\n",
        "# List of file base names and sizes\n",
        "data_name = [\n",
        "    \"data0_pP08_0\", \"data1_pP08_0\", \"data2_pP10_1\", \"data3_pP10_0\", \"data4_pP12_1\",\n",
        "    \"data5_pP12_1\", \"data6_pP13_0\", \"data7_pP13_0\", \"data8_pP14_0\", \"data9_pP15_0\",\n",
        "    \"data10_pP15_1\", \"data11_pP16_0\", \"data12_pP16_0\", \"data13_pP17_1\", \"data14_pP17_0\",\n",
        "    \"data15_pP18_1\", \"data16_pP18_1\", \"data17_pP19_1\", \"data18_pP19_1\", \"data19_pP20_0\",\n",
        "    \"data20_pP20_0\", \"data21_pP21_0\", \"data22_pP21_1\", \"data23_pP23_0\", \"data24_pP23_0\",\n",
        "    \"data25_pP24_1\", \"data26_pP24_1\", \"data27_pP25_0\", \"data28_pP27_0\", \"data29_pP28_0\",\n",
        "    \"data30_pP29_0\", \"data31_pP29_0\", \"data32_pP30_1\", \"data33_pP30_1\", \"data34_pP31_0\",\n",
        "    \"data35_pP31_0\", \"data36_pP33_0\", \"data37_pP33_0\", \"data38_pP34_0\", \"data39_pP35_0\",\n",
        "    \"data40_pP35_0\", \"data41_pP36_0\", \"data42_pP38_0\", \"data43_pP38_0\"\n",
        "]\n",
        "data_size = [\n",
        "    9875, 5900, 1638, 2542, 2036, 1085, 7532, 280, 10007, 3509, 2452, 11881, 10347,\n",
        "    1119, 0, 3201, 3412, 465, 497, 2185, 1799, 2481, 2243, 3540, 3440, 5518, 2155,\n",
        "    560, 4, 2890, 13038, 16197, 9036, 10052, 4108, 1423, 7039, 6073, 4153, 7687,\n",
        "    7214, 9576, 3963, 1940\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FErtaZxqh8Ql"
      },
      "source": [
        "# compressing train_data (old)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHhaVLBRMLxP"
      },
      "outputs": [],
      "source": [
        "# open train data (old decompressed)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/train_data_FP.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SI4GkdsevYi"
      },
      "outputs": [],
      "source": [
        "# compress the train_data\n",
        "import pickle\n",
        "import zlib\n",
        "\n",
        "# Save with zlib compression\n",
        "with open(\"train_data_compressed.pkl\", \"wb\") as f:\n",
        "    compressed = zlib.compress(pickle.dumps(train_data))\n",
        "    f.write(compressed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX_XqzM5h3sH"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jZLkozooigF_"
      },
      "outputs": [],
      "source": [
        "# @title file saver/opener\n",
        "import pickle\n",
        "import zlib\n",
        "\n",
        "# Save to compressed file\n",
        "def save_compressed(obj, filename):\n",
        "    with open(filename, \"wb\") as f:\n",
        "        compressed = zlib.compress(pickle.dumps(obj))\n",
        "        f.write(compressed)\n",
        "\n",
        "\n",
        "def load_compressed(filename):\n",
        "    with open(filename, \"rb\") as f:\n",
        "        compressed = f.read()\n",
        "        return pickle.loads(zlib.decompress(compressed))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDgWmSORjdSe"
      },
      "outputs": [],
      "source": [
        "# Examples\n",
        "\n",
        "# Save the grayscaled, float32-compressed images\n",
        "# save_compressed(som_train_img, \"som_train_img_compressed.pkl\")\n",
        "# save_compressed(som_prj_img, \"som_prj_img_compressed.pkl\")\n",
        "\n",
        "# som_train_img = load_compressed(\"som_train_img_compressed.pkl\")\n",
        "# som_prj_img = load_compressed(\"som_prj_img_compressed.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "i9AmkofBhtam"
      },
      "outputs": [],
      "source": [
        "# @title loading train/test data\n",
        "train_data = load_compressed(\"train_data_compressed.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO9NUrZHlUS8"
      },
      "outputs": [],
      "source": [
        "# test data\n",
        "test_data = load_compressed(\"test_data_compressed.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G5LSVxpRTS0",
        "outputId": "62984991-0c27-4625-ef66-2de2046d3c02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total train data: 38\n",
            "\n",
            "-----------------\n",
            "\n",
            "dt_0_P08_0, size: 9875\n",
            "dt_1_P08_0, size: 5900\n",
            "dt_4_P12_1, size: 2036\n",
            "dt_5_P12_1, size: 1085\n",
            "dt_8_P14_0, size: 10007\n",
            "dt_9_P15_0, size: 3509\n",
            "dt_10_P15_1, size: 2452\n",
            "dt_11_P16_0, size: 11881\n",
            "dt_12_P16_0, size: 10347\n",
            "dt_13_P17_1, size: 1119\n",
            "dt_15_P18_1, size: 3201\n",
            "dt_16_P18_1, size: 3412\n",
            "dt_19_P20_0, size: 2185\n",
            "dt_20_P20_0, size: 1799\n",
            "dt_21_P21_0, size: 2481\n",
            "dt_22_P21_1, size: 2243\n",
            "dt_23_P23_0, size: 3540\n",
            "dt_24_P23_0, size: 3440\n",
            "dt_25_P24_1, size: 5518\n",
            "dt_26_P24_1, size: 2155\n",
            "dt_27_P25_0, size: 560\n",
            "dt_29_P28_0, size: 2890\n",
            "dt_30_P29_0, size: 13038\n",
            "dt_31_P29_0, size: 16197\n",
            "dt_32_P30_1, size: 9036\n",
            "dt_33_P30_1, size: 10052\n",
            "dt_34_P31_0, size: 4108\n",
            "dt_35_P31_0, size: 1423\n",
            "dt_36_P33_0, size: 7039\n",
            "dt_37_P33_0, size: 6073\n",
            "dt_38_P34_0, size: 4153\n",
            "dt_39_P35_0, size: 7687\n",
            "dt_40_P35_0, size: 7214\n",
            "dt_41_P36_0, size: 9576\n",
            "dt_42_P38_0, size: 3963\n",
            "dt_43_P38_0, size: 1940\n",
            "dt_6_P13_0, size: 7812\n",
            "dt_17_P19_1, size: 962\n"
          ]
        }
      ],
      "source": [
        "print(f\"total train data: {len(train_data)}\\n\\n-----------------\\n\")\n",
        "for name, data_dict in train_data:\n",
        "    print(f\"{name}, size: {len(data_dict['feature']['contours'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEHjz-RCkb6N",
        "outputId": "3ad215e2-a0c1-44cd-8b8b-1e863dfbd6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total test data: 2\n",
            "\n",
            "-----------------\n",
            "\n",
            "dt_2_P10_1, size: 1638\n",
            "dt_3_P10_0, size: 2542\n"
          ]
        }
      ],
      "source": [
        "print(f\"total test data: {len(test_data)}\\n\\n-----------------\\n\")\n",
        "for name, data_dict in test_data:\n",
        "    print(f\"{name}, size: {len(data_dict['feature']['contours'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zLAsFUD7NVCe"
      },
      "outputs": [],
      "source": [
        "# =====================================================================================================\n",
        "# Step: 1, 2, 3\n",
        "# =====================================================================================================\n",
        "\n",
        "# ----------------------------  sample -> split: train, projection  ------------------------------------\n",
        "\n",
        "\n",
        "# Step: 1, 2\n",
        "def decide_sample_size(group_size):\n",
        "    \"\"\"\n",
        "    Decide sample size based on group size.\n",
        "    Returns (sample_size, train_split, projection_split).\n",
        "    \"\"\"\n",
        "    if group_size < 500:\n",
        "        return (0, 0, 0)\n",
        "    elif group_size < 3000:\n",
        "        return (500, 1, 0)\n",
        "    elif group_size < 5000:\n",
        "        return (1000, 1, 1)\n",
        "    elif group_size < 7000:\n",
        "        return (1500, 1, 2)\n",
        "    elif group_size < 8000:\n",
        "        return (2000, 2, 2)\n",
        "    elif group_size < 11000:\n",
        "        return (2500, 2, 3)\n",
        "    elif group_size <= 20000:\n",
        "        return (3000, 3, 3)\n",
        "    else:\n",
        "        n = round((0.15 * group_size) / 500)\n",
        "        sample_size = n * 500\n",
        "        if n % 2 == 0:\n",
        "            return (sample_size, n // 2, n // 2)\n",
        "        else:\n",
        "            return (sample_size, (n - 1) // 2, (n + 1) // 2)\n",
        "\n",
        "\n",
        "\n",
        "# train_data = [(name, dict)], m size list\n",
        "# dict =\n",
        "        # 'feature': {\n",
        "        #     'contours': contours_list\n",
        "        #     'au': au_list\n",
        "        #     'landmarks': landmarks_list\n",
        "        #     'headEulerAngle': headEulerAngle_list\n",
        "        #     'classification': classification_list\n",
        "        # },\n",
        "        # 'ground_truth': 0 or 1\n",
        "\n",
        "\n",
        "# make indices for sample\n",
        "def sample_uniformly(size, num_samples=500):\n",
        "    \"\"\"\n",
        "    Randomly selects 'num_samples' indices from the dataset in a uniform manner.\n",
        "\n",
        "    Args:\n",
        "        size (int): Total number of data points in the dataset.\n",
        "        num_samples (int): Number of samples to select (default: 500).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: An array of sampled indices.\n",
        "    \"\"\"\n",
        "    # Ensure sample size doesn't exceed available data\n",
        "    num_samples = min(size, num_samples)\n",
        "    # Select 'num_samples' unique indices uniformly without a fixed seed within 'size'\n",
        "    sampled_indices = np.random.choice(size, num_samples, replace=False)\n",
        "    return sampled_indices\n",
        "\n",
        "\n",
        "# get data from samples indexes\n",
        "def get_sample_data(data_dict, sampled_indices):\n",
        "    \"\"\"\n",
        "    Extracts a subset of data using sampled indices.\n",
        "\n",
        "    Args:\n",
        "        data_dict (dict): Dictionary containing 'feature' and its sub-keys.\n",
        "        sampled_indices (list): List of sampled indices.\n",
        "\n",
        "    Returns:\n",
        "        dict: A new dictionary containing only the sampled data.\n",
        "    \"\"\"\n",
        "    sampled_data = {\n",
        "        'sample': sampled_indices,\n",
        "        'feature': {\n",
        "            'contours': [data_dict['feature']['contours'][i] for i in sampled_indices],\n",
        "            'au': [data_dict['feature']['au'][i] for i in sampled_indices],\n",
        "            'landmarks': [data_dict['feature']['landmarks'][i] for i in sampled_indices],\n",
        "            'headEulerAngle': [data_dict['feature']['headEulerAngle'][i] for i in sampled_indices],\n",
        "            'classification': [data_dict['feature']['classification'][i] for i in sampled_indices],\n",
        "        },\n",
        "        'ground_truth': data_dict['ground_truth']\n",
        "    }\n",
        "    return sampled_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Lu4wQpfrN3Ct"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- {name: idx} dictionary  ---\n",
        "# Build once, after train_data is loaded\n",
        "name_to_index = {name: idx for idx, (name, _) in enumerate(train_data)}\n",
        "\n",
        "def get_index_by_name(name):\n",
        "    return name_to_index.get(name, -1)  # or raise an error if you prefer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "obpH-3t8OBr8"
      },
      "outputs": [],
      "source": [
        "# --- Sampling Loop ---\n",
        "# store these idx in metadata\n",
        "som_train_idx = []\n",
        "som_prj_idx = []\n",
        "\n",
        "# lists of tuples like [(name, sampled_indices)]\n",
        "for name, data_dict in train_data:\n",
        "    data_size = len(data_dict['feature']['contours'])\n",
        "    _, num_train, num_prj = decide_sample_size(data_size)\n",
        "\n",
        "    for _ in range(num_train):\n",
        "        indices = sample_uniformly(data_size, 500)\n",
        "        som_train_idx.append((name, indices.tolist()))\n",
        "\n",
        "    for _ in range(num_prj):\n",
        "        indices = sample_uniformly(data_size, 500)\n",
        "        som_prj_idx.append((name, indices.tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-zEBuq6Oc0i",
        "outputId": "768fdb07-80dd-487d-cc9c-dc21318ea2b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(som_train_idx[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMw67bjWRplT",
        "outputId": "02de9b89-39a1-4253-fa93-ae31f50f50a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dt_0_P08_0\t[4280, 4345, 5526, 1569, 2906, 7521, 900, 2461, 4328, 6893]\n",
            "dt_0_P08_0\t[5391, 3857, 3362, 5783, 3974, 1115, 4295, 7395, 2077, 814]\n",
            "dt_1_P08_0\t[4282, 3587, 2353, 1358, 1996, 2393, 1288, 464, 3892, 5045]\n",
            "dt_4_P12_1\t[358, 38, 1715, 744, 224, 1097, 1221, 826, 1502, 1743]\n",
            "dt_5_P12_1\t[768, 302, 363, 866, 726, 560, 1048, 1005, 214, 529]\n",
            "dt_8_P14_0\t[8377, 2573, 6088, 1604, 5622, 7232, 2774, 5218, 2863, 2725]\n",
            "dt_8_P14_0\t[7395, 502, 1460, 9689, 4176, 6097, 4958, 5227, 775, 2345]\n",
            "dt_9_P15_0\t[2477, 2573, 875, 2083, 1041, 2732, 663, 3479, 703, 2023]\n",
            "dt_10_P15_1\t[590, 2034, 1581, 1044, 324, 690, 533, 771, 714, 2204]\n",
            "dt_11_P16_0\t[4938, 5326, 317, 4078, 3665, 10114, 9481, 4113, 581, 2114]\n",
            "dt_11_P16_0\t[6336, 10866, 2128, 1096, 1784, 6296, 10995, 7747, 11763, 10344]\n",
            "dt_11_P16_0\t[7722, 6151, 9043, 9436, 4284, 9233, 3862, 515, 10847, 9039]\n",
            "dt_12_P16_0\t[5111, 5169, 163, 1177, 2352, 4457, 502, 8513, 9474, 4126]\n",
            "dt_12_P16_0\t[3574, 6898, 10189, 5031, 8200, 6562, 5512, 7257, 588, 416]\n",
            "dt_13_P17_1\t[716, 157, 518, 574, 332, 886, 696, 687, 660, 868]\n",
            "dt_15_P18_1\t[213, 2234, 1346, 3081, 2384, 2450, 1180, 2913, 329, 391]\n",
            "dt_16_P18_1\t[2887, 999, 2528, 1711, 675, 3215, 560, 737, 2986, 3234]\n",
            "dt_19_P20_0\t[1277, 626, 1926, 144, 836, 42, 1384, 599, 773, 1441]\n",
            "dt_20_P20_0\t[353, 268, 553, 1603, 412, 323, 225, 1712, 1062, 1066]\n",
            "dt_21_P21_0\t[1555, 826, 1241, 1369, 379, 1876, 565, 1120, 1314, 2428]\n",
            "dt_22_P21_1\t[1018, 1835, 739, 289, 336, 522, 1403, 616, 2020, 97]\n",
            "dt_23_P23_0\t[228, 1466, 1362, 2341, 3531, 390, 2273, 928, 316, 3417]\n",
            "dt_24_P23_0\t[1156, 1113, 1788, 3370, 285, 1426, 2552, 3329, 1344, 2693]\n",
            "dt_25_P24_1\t[817, 3157, 2870, 5182, 2415, 1547, 2841, 4700, 951, 3160]\n",
            "dt_26_P24_1\t[565, 869, 1084, 372, 641, 202, 1867, 2025, 1243, 1125]\n",
            "dt_27_P25_0\t[118, 522, 234, 60, 292, 4, 288, 392, 416, 155]\n",
            "dt_29_P28_0\t[2701, 1181, 291, 2143, 2100, 1145, 1243, 2065, 2835, 1989]\n",
            "dt_30_P29_0\t[11442, 409, 6491, 11522, 12615, 12380, 9596, 7067, 350, 94]\n",
            "dt_30_P29_0\t[9958, 162, 6931, 6751, 1810, 4661, 8943, 3756, 3851, 11126]\n",
            "dt_30_P29_0\t[5142, 11569, 12762, 9025, 5754, 41, 5617, 10993, 2498, 4191]\n",
            "dt_31_P29_0\t[13434, 10302, 929, 10075, 3084, 5323, 8713, 3999, 10811, 3593]\n",
            "dt_31_P29_0\t[10378, 10928, 10450, 15845, 9722, 12270, 10066, 3416, 15569, 14115]\n",
            "dt_31_P29_0\t[9267, 14163, 16123, 9172, 10585, 13635, 11163, 9339, 5271, 2615]\n",
            "dt_32_P30_1\t[3727, 7580, 8641, 5607, 2362, 3980, 6998, 4157, 5482, 6122]\n",
            "dt_32_P30_1\t[1337, 1272, 148, 3510, 5692, 2592, 8446, 2629, 8107, 3741]\n",
            "dt_33_P30_1\t[6171, 4097, 8571, 4116, 467, 6406, 8722, 8890, 2173, 8344]\n",
            "dt_33_P30_1\t[2967, 4977, 6903, 8180, 9079, 5504, 4156, 9549, 8898, 6459]\n",
            "dt_34_P31_0\t[4074, 3884, 1392, 3199, 3370, 2582, 2663, 1437, 906, 2490]\n",
            "dt_35_P31_0\t[835, 621, 651, 1258, 1145, 382, 880, 811, 659, 1142]\n",
            "dt_36_P33_0\t[289, 1543, 3235, 1564, 4207, 2836, 4132, 3122, 2300, 4383]\n",
            "dt_36_P33_0\t[5523, 2715, 5380, 4794, 2164, 6029, 4158, 6778, 5674, 3484]\n",
            "dt_37_P33_0\t[548, 768, 107, 3627, 2374, 4351, 2753, 5119, 2560, 5404]\n",
            "dt_38_P34_0\t[1524, 533, 2540, 3054, 1898, 3143, 14, 1173, 3535, 2839]\n",
            "dt_39_P35_0\t[2936, 6938, 6602, 533, 5331, 5741, 6347, 3218, 12, 1956]\n",
            "dt_39_P35_0\t[4217, 2787, 4527, 3716, 3600, 6927, 5645, 6796, 3386, 4564]\n",
            "dt_40_P35_0\t[4080, 828, 2109, 90, 4470, 5311, 1393, 5753, 972, 2892]\n",
            "dt_40_P35_0\t[3511, 537, 573, 888, 5263, 4380, 5582, 7092, 592, 3648]\n",
            "dt_41_P36_0\t[8895, 6514, 3626, 3154, 6039, 3558, 2604, 6917, 7343, 117]\n",
            "dt_41_P36_0\t[1675, 7439, 8959, 1044, 4094, 3724, 6122, 7398, 5610, 7299]\n",
            "dt_42_P38_0\t[753, 2214, 1359, 3907, 1387, 3688, 1022, 2415, 3551, 681]\n",
            "dt_43_P38_0\t[1778, 142, 573, 9, 565, 1915, 1904, 1003, 1036, 1932]\n",
            "dt_6_P13_0\t[6599, 1261, 2018, 6043, 3343, 1201, 3292, 5991, 2192, 7606]\n",
            "dt_6_P13_0\t[4818, 3413, 4760, 7370, 3572, 1008, 6037, 6728, 2716, 3026]\n",
            "dt_17_P19_1\t[555, 871, 961, 577, 883, 287, 364, 145, 25, 297]\n"
          ]
        }
      ],
      "source": [
        "for dt_nm, dt_idx in som_train_idx:\n",
        "    print(f\"{dt_nm}\\t{dt_idx[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh7p0lsBO4y-"
      },
      "outputs": [],
      "source": [
        "# Step: 3\n",
        "# ----  update \"sample metadata\" here  ----\n",
        "# Store the \"som metadata\" after SOM & Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OlWLt6WjUmlO"
      },
      "outputs": [],
      "source": [
        "# @title Get Sample\n",
        "# SAMPLE: getting samples using above som_train_idx and som_prj_idx\n",
        "som_train_samples = []\n",
        "som_prj_samples = []\n",
        "\n",
        "for name, indices in som_train_idx:\n",
        "    data_idx = get_index_by_name(name)\n",
        "    nm, dt_dict = train_data[data_idx]\n",
        "    som_train_samples.append((name, indices, get_sample_data(dt_dict, indices)))\n",
        "\n",
        "for name, indices in som_prj_idx:\n",
        "    data_idx = get_index_by_name(name)\n",
        "    nm, dt_dict = train_data[data_idx]\n",
        "    som_prj_samples.append((name, indices, get_sample_data(dt_dict, indices)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hoRo3Dtdlr6Z"
      },
      "outputs": [],
      "source": [
        "# save the sample (to avoid colab runtime crushing), before \"kernel restart-p1\"\n",
        "import pickle\n",
        "\n",
        "# Group both sample lists into a dictionary\n",
        "som_data = {\n",
        "    'train_samples': som_train_samples,\n",
        "    'prj_samples': som_prj_samples\n",
        "}\n",
        "\n",
        "# Save to a normal pickle\n",
        "# with open('train_som_iteration_1.pkl', 'wb') as f:\n",
        "#     pickle.dump(som_data, f)\n",
        "\n",
        "# Save with zlib compression, pickle file\n",
        "with open(\"train_som_iteration_3.pkl\", \"wb\") as f:\n",
        "    compressed = zlib.compress(pickle.dumps(som_data))\n",
        "    f.write(compressed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0BIk85KmP0C"
      },
      "outputs": [],
      "source": [
        "# @title Restart RUNTIME/Kernel: part 1\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# This will crash the current runtime\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FD2Nz1g_m6V7"
      },
      "outputs": [],
      "source": [
        "# @title Reload SAMPLE\n",
        "import pickle\n",
        "\n",
        "som_data = load_compressed(\"train_som_iteration_3.pkl\")\n",
        "\n",
        "som_train_samples = som_data['train_samples']\n",
        "som_prj_samples = som_data['prj_samples']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quJ31SWIWqL5"
      },
      "source": [
        "___\n",
        "___\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BNoksyC1WwY8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =====================================================================================================\n",
        "# Step: 4, 5, 6, 7, 8\n",
        "# =====================================================================================================\n",
        "# ----  sample contour and transform to image  ----\n",
        "# do the same format using extracted som_train_samples, som_prj_samples:\n",
        "    # som_train_contour = [(name, indices, contours_list_list)]\n",
        "    # som_train_img = [(name, indices, img_lis)]\n",
        "    # som_prj_contour = [(name, indices, contours_list_list)]\n",
        "    # som_prj_img = [(name, indices, img_lis)]\n",
        "\n",
        "    # use  som_train_samples, som_prj_samples to extract the contours\n",
        "    # use convert_to_img(contours) to image conversion\n",
        "\n",
        "# Define image size\n",
        "image_size = 64\n",
        "\n",
        "def convert_to_img(X):\n",
        "    x_coords = np.array([point['x'] for point in X])\n",
        "    y_coords = np.array([point['y'] for point in X])\n",
        "\n",
        "    # Min-max scaling for x and y independently\n",
        "    x_min, x_max = x_coords.min(), x_coords.max()\n",
        "    y_min, y_max = y_coords.min(), y_coords.max()\n",
        "\n",
        "    x_normalized = (x_coords - x_min) / (x_max - x_min)\n",
        "    y_normalized = (y_coords - y_min) / (y_max - y_min)\n",
        "\n",
        "    landmarks = np.column_stack((x_normalized, y_normalized))\n",
        "\n",
        "    # Scale normalized landmarks to fit within the 64x64 image\n",
        "    landmarks_scaled = np.round(landmarks * (image_size - 1)).astype(int)\n",
        "\n",
        "    face_parts = [\n",
        "        # ((0, 35), 'Face oval', (255, 255, 0, 128)),  # Yellow\n",
        "        ((36, 40), 'Left eyebrow (top)', (0, 0, 255, 128)),  # Blue\n",
        "        ((41, 45), 'Left eyebrow (bottom)', (0, 0, 255, 128)),\n",
        "        ((46, 50), 'Right eyebrow (top)', (128, 0, 128, 128)),  # Purple\n",
        "        ((51, 55), 'Right eyebrow (bottom)', (128, 0, 128, 128)),\n",
        "        ((56, 71), 'Left eye', (255, 0, 0, 128)),  # Red\n",
        "        ((72, 87), 'Right eye', (255, 0, 0, 128)),\n",
        "        ((88, 96), 'Upper lip (bottom)', (255, 165, 0, 128)),  # Orange\n",
        "        ((97, 105), 'Lower lip (top)', (255, 165, 0, 128)),\n",
        "        ((106, 116), 'Upper lip (top)', (0, 255, 255, 128)),  # Cyan\n",
        "        ((117, 125), 'Lower lip (bottom)', (0, 255, 255, 128)),\n",
        "        ((131, 131), 'Left cheek (center)', (128, 128, 128, 128)),  # Gray\n",
        "        ((132, 132), 'Right cheek (center)', (255, 192, 203, 128)),  # Pink\n",
        "    ]\n",
        "\n",
        "    # Create a blank RGBA image\n",
        "    img = Image.new(\"RGBA\", (image_size, image_size), (0, 0, 0, 0))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    for indices, label, color in face_parts:\n",
        "        start, end = indices\n",
        "        region_points = [(x, y) for x, y in landmarks_scaled[start:end + 1]]\n",
        "\n",
        "        # Fill the polygon formed by the region points\n",
        "        if len(region_points) > 2:  # At least 3 points required to form a polygon\n",
        "            draw.polygon(region_points, fill=color)\n",
        "\n",
        "    # Convert to numpy array and normalize to 0-1 range (RGB only)\n",
        "    img_array = np.array(img)[:, :, :3] / 255.0  # Exclude alpha channel, normalize RGB\n",
        "    return img_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1RhnWvHW72t5"
      },
      "outputs": [],
      "source": [
        "from skimage.color import rgb2gray\n",
        "import numpy as np\n",
        "\n",
        "som_train_img = []\n",
        "som_prj_img = []\n",
        "\n",
        "for name, indices, sample_dict in som_train_samples:\n",
        "    contours_list = sample_dict['feature']['contours']\n",
        "\n",
        "    # Convert contours to images and grayscale float32\n",
        "    gray_list = [\n",
        "        rgb2gray(np.array(convert_to_img(contour))).astype(np.float32)\n",
        "        for contour in contours_list\n",
        "    ]\n",
        "    # som_train_img.append((name, indices, gray_list, contours_list))\n",
        "    som_train_img.append((name, indices, gray_list))\n",
        "\n",
        "\n",
        "for name, indices, sample_dict in som_prj_samples:\n",
        "    contours_list = sample_dict['feature']['contours']\n",
        "\n",
        "    # Convert contours to images and grayscale float32\n",
        "    gray_list = [\n",
        "        rgb2gray(np.array(convert_to_img(contour))).astype(np.float32)\n",
        "        for contour in contours_list\n",
        "    ]\n",
        "    # som_prj_img.append((name, indices, gray_list, contours_list))\n",
        "    som_prj_img.append((name, indices, gray_list))\n",
        "\n",
        "# Note: contours, not included for minimal file size and minimum RAM load\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC_qoXFF_9ev",
        "outputId": "735d85dd-3452-42bd-9599-b94460dd7277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n",
            "3\n",
            "10\n",
            "500\n",
            "500\n",
            "[4176, 6264, 5726, 4807, 2639, 1002, 8479, 1549, 2686, 6254]\n",
            "64\n",
            "64\n"
          ]
        }
      ],
      "source": [
        "print(len(som_prj_img))\n",
        "print(len(som_prj_img[0]))\n",
        "print(len(som_prj_img[0][0]))\n",
        "print(len(som_prj_img[0][1]))   # 500 index\n",
        "print(len(som_prj_img[0][2]))   # 500 64x64 image\n",
        "print(som_prj_img[0][1][490:500])   # 500 index\n",
        "print(len(som_prj_img[0][2][0]))   # 500 64x64 image\n",
        "print(len(som_prj_img[0][2][0][2]))   # 500 64x64 image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8-H7fZARpZZT"
      },
      "outputs": [],
      "source": [
        "# save the image data for a iteration before \"training\" and \"kernel restart-p2\"\n",
        "import numpy as np\n",
        "from skimage.color import rgb2gray\n",
        "import pickle\n",
        "import zlib\n",
        "\n",
        "# Dictionary of the data you want to save\n",
        "image_data = {\n",
        "    'train_img': som_train_img,\n",
        "    'prj_img': som_prj_img\n",
        "}\n",
        "\n",
        "# Save with zlib compression\n",
        "save_compressed(image_data, \"train_som_iteration_3_img.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_sFzRduGAMs"
      },
      "outputs": [],
      "source": [
        "# @title Restart RUNTIME/Kernel: part 2\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# This will crash the current runtime\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eD7jUG-PJ8PO"
      },
      "outputs": [],
      "source": [
        "som_img = load_compressed(\"train_som_iteration_3_img.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BvRin-PaM3yL"
      },
      "outputs": [],
      "source": [
        "# reload the img list\n",
        "som_train_img = som_img['train_img']\n",
        "som_prj_img = som_img['prj_img']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB6DGS2cJrEK"
      },
      "source": [
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiDsU20hEeA_"
      },
      "outputs": [],
      "source": [
        "# @title compress the data using \"zlib\"\n",
        "# saves the as is (not recomended)\n",
        "with open(\"train_som_iteration_1_no_cmprs.pkl\", \"wb\") as f:\n",
        "    pickle.dump(data_to_save, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKGc6LDrE5Ux"
      },
      "outputs": [],
      "source": [
        "# saves the as compressed\n",
        "with open(\"train_som_iteration_1_cmprs.pkl\", \"wb\") as f:\n",
        "    cmpr = zlib.compress(pickle.dumps(data_to_save))\n",
        "    f.write(cmpr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5p5CB7dMmQB"
      },
      "source": [
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rt2b-pfNjes",
        "outputId": "de804efb-0f30-4922-d9e5-5937b7ef586e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# list of tuple = (name, indices, gray_list)\n",
        "len(som_train_img[0][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hPsv9oSsnuU",
        "outputId": "c2e72261-2a64-40d7-c23f-52594f343530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 64)\n"
          ]
        }
      ],
      "source": [
        "np_img = np.array(som_train_img[0][2][0])\n",
        "print(np_img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "ZGtGpLHHemwI",
        "outputId": "c7cee808-fea3-4b6d-d4c3-20c35f2cfd74"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# testing image conversion\n",
        "imme = som_train_img[0][2][0]\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(imme, cmap='gray')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Facial Landmarks & Contours for data_3[0]\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "f-MaxugLr0vp",
        "outputId": "4e1ff88e-fceb-4906-c60b-08641d3d4a80"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the image\n",
        "plt.imshow(np_img, cmap='gray')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Facial Landmarks & Contours for data_3[0]\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYtKua_ltVmd",
        "outputId": "86f88470-21bf-45df-e1ff-30a1bfac0ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min value: 0.0, Max value: 0.7875000238418579\n"
          ]
        }
      ],
      "source": [
        "# How to Check if Normalization is Needed:\n",
        "    # Normalize if the range is [0, 255].\n",
        "    # Skip normalization if the values are already in [0, 1].\n",
        "\n",
        "print(f\"Min value: {np_img.min()}, Max value: {np_img.max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOEgMu3t6Qjk",
        "outputId": "a33843cb-80e4-43ef-9e09-67a187706057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64)\n",
            "\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.2125     0.2125\n",
            " 0.2125     0.2125     0.2125     0.2125     0.2125     0.2125\n",
            " 0.2125     0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.14285804 0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.7875     0.7875     0.         0.         0.         0.\n",
            " 0.7875     0.7875     0.7875     0.7875     0.7875     0.7875\n",
            " 0.67540586 0.67540586 0.67540586 0.         0.         0.\n",
            " 0.         0.         0.67540586 0.67540586 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X1_gray = np_img\n",
        "# Examin the values\n",
        "print(f\"{X1_gray.shape}\\n\")\n",
        "print(f\"{X1_gray[0]}\\n\")\n",
        "print(f\"{X1_gray[21]}\\n\")\n",
        "print(f\"{X1_gray[32]}\\n\")\n",
        "print(f\"{X1_gray[48]}\\n\")\n",
        "print(f\"{X1_gray[63]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCcA8DbcRa3w"
      },
      "source": [
        "# CHECKPONT: som training\n",
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sgZNwOPTmfQ",
        "outputId": "08f731c4-2843-4330-b0bd-b070c337038a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: minisom in /usr/local/lib/python3.11/dist-packages (2.3.5)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title -------- Train the Uni-Ref-SOM --------\n",
        "\n",
        "# --------  Install minisom if not already installed  --------\n",
        "!pip install minisom\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "from minisom import MiniSom\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfhMdc9OTwxZ",
        "outputId": "edd1d3ad-e755-4202-d354-fecbde22cb2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 27000\n",
            "Each image vector shape: (27000, 4096)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ------------------------  PART 1: train a reference SOM   ------------------------\n",
        "\n",
        "# GOAL: Extract and combine all grayscale images from som_train_img\n",
        "#       Combine all images (49 items × 500 = 24,500 images) and train a SOM to define universal clusters.\n",
        "# Format: som_train_img = [(name, indices, [img1, img2, ..., img500]), ...]\n",
        "\n",
        "# Step 1: Flatten the grayscale image data (64x64) to 1D vectors (4096)\n",
        "flat_all = []\n",
        "\n",
        "for name, indices, gray_images in som_train_img:\n",
        "    for img in gray_images:\n",
        "        flat_all.append(img.reshape(-1))  # shape becomes (4096,)\n",
        "\n",
        "# Convert to NumPy array\n",
        "flat_all = np.array(flat_all)  # shape: (total_samples, 4096)\n",
        "\n",
        "# Optional: Check shapes\n",
        "print(\"Total samples:\", len(flat_all))\n",
        "print(\"Each image vector shape:\", flat_all.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcp43f1NUFlK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --------  Train universal SOM (e.g., 10x10 grid = 100 clusters)  --------\n",
        "# \"size\" & \"iteration\" fixing for SOM neuron (TUNING 1):\n",
        "\n",
        "# size: we set 11x11, considering 500 sample size for each individual\n",
        "    #   i.e. 121 clusters for 500 individual, 1 node for 4 data-point\n",
        "    #   because our goal was making a SOM for each sample of 500 data.\n",
        "    #   5*sqrt(500) = 5*22.4 = 112 : 11*11 or 10*10\n",
        "\n",
        "# iterations: we set initially 3000 (took 10s train), 7000(23s), 10000(36s), 60500 (240s), 70000(300s), 85000(347), 100000(400s)\n",
        "# 123000 iteration, train time (540s)\n",
        "\n",
        "som_universal = MiniSom(11, 11, input_len=flat_all.shape[1], sigma=1.0, learning_rate=0.5, random_seed=42)\n",
        "som_universal.train_random(flat_all, num_iteration=123000)\n",
        "# we used \"random_seed=42\" so that random weight initialization is fixed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For TEST, small train\n",
        "som_universal = MiniSom(11, 11, input_len=flat_all.shape[1], sigma=1.0, learning_rate=0.5, random_seed=42)\n",
        "som_universal.train_random(flat_all, num_iteration=20000)"
      ],
      "metadata": {
        "id": "vjNi1XNZievQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xtmzSdZSUlWQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Assign Clusters, Sample projection, probability vector creation\n",
        "\n",
        "# ------------------------  PART 2: Project samples onto the Universal SOM   ------------------------\n",
        "# PART 2 GOAL:\n",
        "    # 1.    Project Individual Images onto the Universal SOM\n",
        "    # 2.    Create a probability vector (stochastic vector) for each individual based on the number of images assigned to each cluster.\n",
        "\n",
        "\n",
        "# Project Individual Images onto the Universal SOM\n",
        "    # For each individual, map their images to the universal SOM's nodes to ensure consistent group labels.\n",
        "\n",
        "def assign_clusters(images, som):\n",
        "    # Flatten images (shape: 500, 64, 64) -> (500, 4096)\n",
        "    flat_img = images.reshape(500, -1)\n",
        "\n",
        "    # Assign clusters using the universal SOM (map each image to its best-matching SOM node)\n",
        "    cluster_labels = np.array([som.winner(x) for x in flat_img])\n",
        "    # Unique cluster IDs: Convert node coordinates to unique integers (e.g., (row*11 + col))\n",
        "        # for 11x11 som the formula is: row * 11 + col\n",
        "    cluster_ids = np.array([row * 11 + col for (row, col) in cluster_labels])\n",
        "\n",
        "    # If your SOM size changes dynamically, use:\n",
        "    # grid_size_x = som.x  # Number of columns\n",
        "    # cluster_ids = np.array([row * grid_size_x + col for (row, col) in cluster_labels])\n",
        "\n",
        "    # or\n",
        "    # cluster_ids = np.array([row * som.x + col for (row, col) in cluster_labels])\n",
        "\n",
        "    return cluster_ids\n",
        "\n",
        "\n",
        "# NOTE: for a single input x, som.winner(x) returns only one pair of coordinates (row, col)\n",
        "    # So cluster_labels in our code is a \"list of (x, y) coordinate pairs\", where:\n",
        "        # x represents the \"row index\" of the SOM grid.\n",
        "        # y represents the \"column index\" of the SOM grid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr7gmES2Uz5K",
        "outputId": "9406f09a-4185-40cc-e1c0-43606ebe394f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dt_1_P08_0\t[5726, 4170, 3715, 4093, 371, 4089, 4741, 3379, 3143, 3534]\n",
            "dt_4_P12_1\t[1624, 1025, 474, 918, 75, 2018, 1374, 1593, 1686, 147]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# @title --------  cluster assign: preview  --------\n",
        "# Task:\n",
        "    # get the clusters for each of 49 items also\n",
        "    # group the index of image according to clusters -> find the group of original indices\n",
        "    # use \"sampled indices\"\n",
        "\n",
        "# we'll test index 2 and 3 (i.e. items 3 & 4)\n",
        "# dt_1_P08_0    [5726, 4170, 3715, 4093, 371, 4089, 4741, 3379, 3143, 3534]\n",
        "# dt_4_P12_1    [1624, 1025, 474, 918, 75, 2018, 1374, 1593, 1686, 147]\n",
        "# images = np.array(images)   # convert image to np-array\n",
        "\n",
        "# Assign clusters for item 3\n",
        "print(f\"{som_train_img[2][0]}\\t{som_train_img[2][1][:10]}\")\n",
        "item3_images = np.array(som_train_img[2][2])      # Shape (500, 64, 64)\n",
        "item3_clusters_ids = assign_clusters(item3_images, som_universal)\n",
        "\n",
        "# # Assign clusters for item 4\n",
        "print(f\"{som_train_img[3][0]}\\t{som_train_img[3][1][:10]}\")\n",
        "item4_images = np.array(som_train_img[3][2])      # Shape (500, 64, 64)\n",
        "item4_clusters_ids = assign_clusters(item4_images, som_universal)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(item3_images.shape)\n",
        "print(item4_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bRTr6--mWQp",
        "outputId": "4a468631-046e-46da-f5cc-a400a8663ea4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 64, 64)\n",
            "(500, 64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "XBjWNTJKWm7n",
        "outputId": "8c7911d4-4927-4aac-b8d3-0825e022b6e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Analyze Cluster Consistency\n",
        "    # Check if the clusters for individual 4 align with those for individual 5\n",
        "    # Visualize the clusters to ensure they group similar expressions across individuals.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize cluster assignments for individual 0\n",
        "plt.hist(item3_clusters_ids, bins=121, alpha=0.5, label='Person 4')\n",
        "plt.hist(item4_clusters_ids, bins=121, alpha=0.5, label='Person 5')\n",
        "plt.xlabel('Cluster ID')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lDaW4Q_U10w",
        "outputId": "52cc5870-cdcb-4214-aae2-1793c489474c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# @title ==================    vizualization    ===============================\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Unique colors for each person (red tint for Person 4, blue tint for Person 5)\n",
        "# person 4's index is 3,  and person 5's index is 4\n",
        "color_maps = {3: 'Reds', 4: 'Blues'}  # Individual 4 → Red, Individual 5 → Blue\n",
        "\n",
        "# Store data separately for each person\n",
        "individuals = {3: item3_images, 4: item4_images}\n",
        "individual_cluster_ids = {3: item3_clusters_ids, 4: item4_clusters_ids}\n",
        "\n",
        "# Define the total number of possible clusters (e.g., 121 for an 11x11 SOM)\n",
        "n_possible_clusters = 121\n",
        "num_persons = len(individuals)\n",
        "\n",
        "# Step 1: Compute Prototypes & Cluster Data for Each Person for ALL possible clusters\n",
        "prototypes = {}         # keys: (person_id, cluster_id)\n",
        "cluster_counts = {}     # keys: (person_id, cluster_id)\n",
        "cluster_images_dict = {}  # keys: (person_id, cluster_id)\n",
        "\n",
        "for person_id in individuals:\n",
        "    images = individuals[person_id]\n",
        "    cluster_ids = individual_cluster_ids[person_id]\n",
        "    # Determine image shape from the first image (assumes at least one image exists)\n",
        "    image_shape = images[0].shape\n",
        "\n",
        "    for cluster_id in range(n_possible_clusters):\n",
        "        key = (person_id, cluster_id)\n",
        "        # Check if this cluster exists in the current person's data\n",
        "        if cluster_id in np.unique(cluster_ids):\n",
        "            cluster_imgs = images[cluster_ids == cluster_id]\n",
        "            # images: A NumPy array of shape (500, 64, 64) — contains 500 face images for a person.\n",
        "            # cluster_ids: A NumPy array of shape (500,) — contains the SOM cluster ID (0–120) for each of those 500 images.\n",
        "            # cluster_ids == cluster_id creates a boolean mask of shape (500,) [False, True, False, ..., True]\n",
        "            # What images[mask] does: Selects the subset of images where the corresponding cluster_id matches the current cluster.\n",
        "            prototype = np.mean(cluster_imgs, axis=0)\n",
        "            prototypes[key] = prototype\n",
        "            cluster_counts[key] = len(cluster_imgs)\n",
        "            cluster_images_dict[key] = cluster_imgs # saves the cluster of images\n",
        "        else:\n",
        "            # For empty clusters, assign an empty (all-zero) image\n",
        "            prototypes[key] = np.zeros(image_shape)\n",
        "            cluster_counts[key] = 0\n",
        "            cluster_images_dict[key] = np.empty((0, *image_shape))\n",
        "\n",
        "# Determine maximum number of images in any cluster across all individuals\n",
        "max_n = min(max(cluster_counts.values()), 10) if cluster_counts else 0\n",
        "print(max_n)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total columns: each cluster has one column per person\n",
        "total_columns = n_possible_clusters * num_persons\n",
        "total_rows = max_n + 1  # First row for prototypes\n",
        "\n",
        "# Create a grid for visualization (adjust figsize as needed)\n",
        "# To increase the size of the images in the visualization, modify the \"figsize\" parameter in the plt.subplots() function.\n",
        "# currently 0.5 -> 2\n",
        "fig, axes = plt.subplots(total_rows, total_columns, figsize=(total_columns * 1, total_rows * 1))\n",
        "\n",
        "# Step 2: Visualize: For each possible cluster, show each person's prototype and images side by side\n",
        "for cluster_id in range(n_possible_clusters):\n",
        "    for person_id in individuals:\n",
        "        col_idx = cluster_id * num_persons + person_id -3\n",
        "        key = (person_id, cluster_id)\n",
        "        cmap = color_maps[person_id]\n",
        "\n",
        "        # Plot prototype in the first row\n",
        "        axes[0, col_idx].imshow(prototypes[key], cmap=cmap)\n",
        "        count = cluster_counts[key]\n",
        "        axes[0, col_idx].set_title(f'P{person_id} C{cluster_id}\\n(n={count})', fontsize=6)\n",
        "        axes[0, col_idx].axis('off')\n",
        "\n",
        "        # Plot each image below the prototype (or an empty image if none available)\n",
        "        cluster_imgs = cluster_images_dict[key]\n",
        "        for row_idx in range(max_n):\n",
        "            ax = axes[row_idx + 1, col_idx]\n",
        "            if row_idx < count:\n",
        "                ax.imshow(cluster_imgs[row_idx], cmap=cmap)\n",
        "            else:\n",
        "                ax.imshow(np.zeros_like(prototypes[key]), cmap=cmap)\n",
        "            ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E5TNU28p3MFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FtiaK-6MVTdT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @title ===============    probability (stochastic) vector & saving trained data    ===============\n",
        "\n",
        "# probability_vectors contains the probability vector for each individual.\n",
        "# Note: cluster_ids and person_clusters represent the same data: the cluster assignment for each image of a person.\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "n_clusters = 11*11\n",
        "\n",
        "def compute_probability_vector(cluster_ids, n_clusters):\n",
        "    \"\"\"\n",
        "    Compute both the normalized probability vector and the raw counts vector for an individual based on\n",
        "    the number of images assigned to each cluster (from 0 to n_clusters-1).\n",
        "\n",
        "    Parameters:\n",
        "    - cluster_ids: a NumPy array of cluster IDs assigned to each image.\n",
        "    - n_clusters: total number of possible clusters (e.g., 121 for an 11x11 SOM).\n",
        "\n",
        "    Returns:\n",
        "    - probability_vector: normalized counts (stochastic vector) of length n_clusters.\n",
        "    - counts_vector: raw counts for each cluster, of length n_clusters.\n",
        "    \"\"\"\n",
        "    sample_size = len(cluster_ids)  # Dynamic sample size\n",
        "    counts_vector = np.zeros(n_clusters)  # Initialize raw counts with zeros for all clusters\n",
        "    unique, counts = np.unique(cluster_ids, return_counts=True)  # Get unique cluster IDs and counts (Count occurrences per cluster)\n",
        "    counts_vector[unique] = counts  # Assign counts to corresponding clusters (indices)\n",
        "    probability_vector = counts_vector / sample_size  # Normalize by the sample size\n",
        "    return probability_vector, counts_vector\n",
        "\n",
        "\n",
        "\n",
        "# adjusted like below:\n",
        "\"\"\"\n",
        "                    Now here comes the fun part. Remember the structure of som_train_img?\n",
        "                        We can now drop the images and store only the cluster_ids,\n",
        "                        since we have the real image IDs.\n",
        "\n",
        "                    now we'll do this for both som_train_img and som_prj_img parts\n",
        "\n",
        "                    then we calculate the probability vectors (total 49+52, save the different 2d array)\n",
        "\n",
        "                    save the som too.\n",
        "\n",
        "\n",
        "                    So the new data format to save in file:\n",
        "                    som_trained_data = {\n",
        "                        'train_clustr': array of (name, real_500_idx, cluster_ids_500),\n",
        "                        'prj_clustr': array of (name, real_500_idx, cluster_ids_500),\n",
        "                        'pob_vec_train': probability_vectors,\n",
        "                        'pob_vec_prj': probability_vectors,\n",
        "                        'som_model': som_universal\n",
        "                    }\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Updated Code (post-SOM training, keep simple):\n",
        "# -------- Convert som_train_img and som_prj_img to only cluster info --------\n",
        "\n",
        "def convert_img_list_to_cluster_data(img_list, som_model):\n",
        "    result = []\n",
        "    for name, real_idx, images in img_list:\n",
        "        images = np.array(images)\n",
        "        cluster_ids = assign_clusters(images, som_model)\n",
        "        result.append((name, real_idx, cluster_ids))\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to both training and projection sets\n",
        "train_cluster_data = convert_img_list_to_cluster_data(som_train_img, som_universal)\n",
        "prj_cluster_data = convert_img_list_to_cluster_data(som_prj_img, som_universal)"
      ],
      "metadata": {
        "id": "GaRXnUBHhbQg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Compute probability vectors for each individual --------\n",
        "# use a list of tuples:     prob_vectors = [(name, prob_vec)]\n",
        "\n",
        "def compute_all_probability_vectors(cluster_data, total_clusters=121):\n",
        "    prob_vectors = []  # List of (name, prob_vector) tuples\n",
        "    for name, real_indices, cluster_ids in cluster_data:\n",
        "        prob_vec, _ = compute_probability_vector(cluster_ids, total_clusters)\n",
        "        prob_vectors.append((name, prob_vec))\n",
        "    return prob_vectors\n"
      ],
      "metadata": {
        "id": "KTQecx5qhVF-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute separately for train and projection sets\n",
        "prob_vec_train = compute_all_probability_vectors(train_cluster_data, n_clusters)\n",
        "prob_vec_prj = compute_all_probability_vectors(prj_cluster_data, n_clusters)"
      ],
      "metadata": {
        "id": "XXDj_b3bhgeg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "secAWifqVWJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cff1c1f-b89c-47f9-84fa-84b9e0fa0f20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " SOM, clusters, and probability vectors saved to 'som_trained_data_xx.pkl'\n"
          ]
        }
      ],
      "source": [
        "# -------- Save all in one dictionary --------\n",
        "\n",
        "som_trained_data = {\n",
        "    'train_clustr': train_cluster_data,          # list of (name, real_500_idx, cluster_ids)\n",
        "    'prj_clustr': prj_cluster_data,\n",
        "    'pob_vec_train': prob_vec_train,\n",
        "    'pob_vec_prj': prob_vec_prj,\n",
        "    'som_model': som_universal\n",
        "}\n",
        "\n",
        "save_compressed(som_trained_data, \"som_trained_data_03.pkl\")\n",
        "\n",
        "print(\" SOM, clusters, and probability vectors saved to 'som_trained_data_xx.pkl'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VJd408CNVfCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b0efc96-9cce-424a-c298-327851daed58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SOM Model Loaded: <minisom.MiniSom object at 0x7a4aece01a50>\n",
            "SOM Grid Size: (11, 11)\n",
            "\n",
            "=== Sample of Cluster Assignments (Train) ===\n",
            "Name: dt_0_P08_0\n",
            "Real Image Indices (first 10): [4280, 4345, 5526, 1569, 2906, 7521, 900, 2461, 4328, 6893]\n",
            "Cluster IDs (first 10): [ 54  76  55  97  73  60  98 112  63  32]\n",
            "----------------------------------------\n",
            "Name: dt_0_P08_0\n",
            "Real Image Indices (first 10): [5391, 3857, 3362, 5783, 3974, 1115, 4295, 7395, 2077, 814]\n",
            "Cluster IDs (first 10): [54 64 98 65 60 63 49 31 64 54]\n",
            "----------------------------------------\n",
            "Name: dt_1_P08_0\n",
            "Real Image Indices (first 10): [4282, 3587, 2353, 1358, 1996, 2393, 1288, 464, 3892, 5045]\n",
            "Cluster IDs (first 10): [59 42 42 63 65 43 11 69 22 24]\n",
            "----------------------------------------\n",
            "\n",
            "=== Sample of Cluster Assignments (Project) ===\n",
            "Name: dt_0_P08_0\n",
            "Real Image Indices (first 10): [6386, 7428, 4526, 9277, 6963, 1675, 2357, 3655, 6504, 6876]\n",
            "Cluster IDs (first 10): [ 52 108  64  98  21  85  63  54  65  75]\n",
            "----------------------------------------\n",
            "Name: dt_0_P08_0\n",
            "Real Image Indices (first 10): [651, 6843, 3856, 4446, 8190, 8424, 9520, 8124, 4496, 3705]\n",
            "Cluster IDs (first 10): [43 87 97 54 32 64 97 43 65 32]\n",
            "----------------------------------------\n",
            "Name: dt_0_P08_0\n",
            "Real Image Indices (first 10): [6152, 5991, 4424, 8360, 9714, 2695, 5579, 9059, 3513, 2149]\n",
            "Cluster IDs (first 10): [ 61  42  84 115  64  60  56  42  64  56]\n",
            "----------------------------------------\n",
            "\n",
            "=== Probability Vectors (Train) ===\n",
            "Person: dt_0_P08_0\tLabel: [0.004 0.    0.    0.002 0.    0.    0.    0.    0.002 0.002]\tSum: 1.0000, Min: 0.0000, Max: 0.1040\n",
            "Person: dt_0_P08_0\tLabel: [0.004 0.    0.    0.    0.    0.    0.    0.004 0.    0.   ]\tSum: 1.0000, Min: 0.0000, Max: 0.1240\n",
            "Person: dt_1_P08_0\tLabel: [0.    0.    0.    0.    0.    0.002 0.002 0.    0.002 0.002]\tSum: 1.0000, Min: 0.0000, Max: 0.1060\n",
            "Person: dt_4_P12_1\tLabel: [0.002 0.014 0.022 0.006 0.004 0.024 0.014 0.004 0.004 0.002]\tSum: 1.0000, Min: 0.0000, Max: 0.0280\n",
            "Person: dt_5_P12_1\tLabel: [0.004 0.008 0.006 0.012 0.    0.044 0.024 0.004 0.002 0.022]\tSum: 1.0000, Min: 0.0000, Max: 0.0620\n",
            "Person: dt_8_P14_0\tLabel: [0.006 0.004 0.    0.    0.    0.002 0.002 0.008 0.006 0.012]\tSum: 1.0000, Min: 0.0000, Max: 0.0800\n",
            "Person: dt_8_P14_0\tLabel: [0.004 0.002 0.    0.004 0.    0.006 0.006 0.01  0.004 0.01 ]\tSum: 1.0000, Min: 0.0000, Max: 0.0880\n",
            "Person: dt_9_P15_0\tLabel: [0.012 0.018 0.082 0.034 0.022 0.002 0.004 0.008 0.    0.   ]\tSum: 1.0000, Min: 0.0000, Max: 0.0820\n",
            "Person: dt_10_P15_1\tLabel: [0.004 0.056 0.098 0.022 0.024 0.008 0.008 0.006 0.002 0.   ]\tSum: 1.0000, Min: 0.0000, Max: 0.0980\n",
            "Person: dt_11_P16_0\tLabel: [0.002 0.006 0.002 0.008 0.002 0.026 0.008 0.008 0.004 0.002]\tSum: 1.0000, Min: 0.0000, Max: 0.0680\n",
            "----------------------------------------\n",
            "\n",
            "=== Probability Vectors (Projected) ===\n",
            "Person: dt_0_P08_0\tLabel: [0.004 0.002 0.    0.    0.    0.    0.    0.    0.    0.002]\tSum: 1.0000, Min: 0.0000, Max: 0.0920\n",
            "Person: dt_0_P08_0\tLabel: [0.    0.    0.    0.    0.002 0.    0.    0.    0.    0.   ]\tSum: 1.0000, Min: 0.0000, Max: 0.1080\n",
            "Person: dt_0_P08_0\tLabel: [0.    0.    0.    0.004 0.    0.    0.    0.    0.    0.002]\tSum: 1.0000, Min: 0.0000, Max: 0.0880\n",
            "Person: dt_1_P08_0\tLabel: [0.    0.    0.    0.    0.    0.    0.    0.    0.002 0.004]\tSum: 1.0000, Min: 0.0000, Max: 0.0860\n",
            "Person: dt_1_P08_0\tLabel: [0.    0.    0.    0.    0.    0.    0.    0.002 0.    0.   ]\tSum: 1.0000, Min: 0.0000, Max: 0.1080\n",
            "Person: dt_8_P14_0\tLabel: [0.004 0.006 0.    0.002 0.    0.006 0.002 0.006 0.006 0.012]\tSum: 1.0000, Min: 0.0000, Max: 0.0820\n",
            "Person: dt_8_P14_0\tLabel: [0.002 0.002 0.    0.002 0.    0.004 0.006 0.01  0.012 0.008]\tSum: 1.0000, Min: 0.0000, Max: 0.0820\n",
            "Person: dt_8_P14_0\tLabel: [0.004 0.006 0.002 0.    0.    0.008 0.004 0.006 0.006 0.006]\tSum: 1.0000, Min: 0.0000, Max: 0.0640\n",
            "Person: dt_9_P15_0\tLabel: [0.012 0.008 0.076 0.038 0.018 0.004 0.002 0.01  0.004 0.   ]\tSum: 1.0000, Min: 0.0000, Max: 0.0760\n",
            "Person: dt_11_P16_0\tLabel: [0.006 0.002 0.    0.01  0.004 0.018 0.006 0.006 0.    0.006]\tSum: 1.0000, Min: 0.0000, Max: 0.0860\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ===============    Load the SOM model and probability vector    ===============\n",
        "import pickle\n",
        "\n",
        "# Load the trained SOM model and probability vectors\n",
        "\n",
        "som_trained_data = load_compressed(\"som_trained_data_03.pkl\")\n",
        "\n",
        "# Extract SOM model\n",
        "som_model = som_trained_data['som_model']\n",
        "\n",
        "# Preview loaded SOM model\n",
        "print(f\"SOM Model Loaded: {som_model}\")\n",
        "print(f\"SOM Grid Size: {som_model._weights.shape[:2]}\")  # Typically (11, 11)\n",
        "\n",
        "# Preview a few cluster assignments (Train)\n",
        "print(\"\\n=== Sample of Cluster Assignments (Train) ===\")\n",
        "for name, real_ids, cluster_ids in som_trained_data['train_clustr'][:3]:\n",
        "    print(f\"Name: {name}\")\n",
        "    print(f\"Real Image Indices (first 10): {real_ids[:10]}\")\n",
        "    print(f\"Cluster IDs (first 10): {cluster_ids[:10]}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Preview a few cluster assignments (Project)\n",
        "print(\"\\n=== Sample of Cluster Assignments (Project) ===\")\n",
        "for name, real_ids, cluster_ids in som_trained_data['prj_clustr'][:3]:\n",
        "    print(f\"Name: {name}\")\n",
        "    print(f\"Real Image Indices (first 10): {real_ids[:10]}\")\n",
        "    print(f\"Cluster IDs (first 10): {cluster_ids[:10]}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Preview probability vectors - TRAIN\n",
        "print(\"\\n=== Probability Vectors (Train) ===\")\n",
        "for name, vec_data in som_trained_data['pob_vec_train'][:10]:\n",
        "    print(f\"Person: {name}\\tLabel: {vec_data[:10]}\\tSum: {vec_data.sum():.4f}, Min: {vec_data.min():.4f}, Max: {vec_data.max():.4f}\")\n",
        "\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Preview probability vectors - PROJECTED\n",
        "print(\"\\n=== Probability Vectors (Projected) ===\")\n",
        "for name, vec_data in som_trained_data['pob_vec_prj'][:10]:\n",
        "    print(f\"Person: {name}\\tLabel: {vec_data[:10]}\\tSum: {vec_data.sum():.4f}, Min: {vec_data.min():.4f}, Max: {vec_data.max():.4f}\")\n",
        "\n",
        "print(\"-\" * 40)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}